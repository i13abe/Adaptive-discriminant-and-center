{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load dataset\n",
    "from datasets import Datasets\n",
    "\n",
    "# criterions\n",
    "from ad_cen import AdaptiveCenterLoss\n",
    "from ad_disc import AdaptiveDiscriminantLoss\n",
    "\n",
    "# for network and training\n",
    "from network import Net\n",
    "from network_fit import NetworkFit\n",
    "\n",
    "# to calculate the score\n",
    "import savescore\n",
    "from score import Score\n",
    "from score_calc import ScoreCalc\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to show the histogram and feature mapping\n",
    "import histgram\n",
    "from plot_feature import PlotFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize for  each parameters\n",
    "DATASET = 'MNIST'\n",
    "BATCH_SIZE = 100\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "WEIGHT_DECAY = 0.01\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "SCHEDULER_STEPS = 50\n",
    "SCHEDULER_GAMMA = 0.1\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "EPOCH = 100\n",
    "\n",
    "FEATURE = 100\n",
    "OUTPUTS = 10\n",
    "\n",
    "ALPHA1 = 0.999\n",
    "ALPHA2 = 0.999\n",
    "\n",
    "LAMBDA1 = 0.001\n",
    "LAMBDA2 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the seed\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gpu is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"gpu mode\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"cpu mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of results files\n",
    "codename = 'ad_ac_example'\n",
    "\n",
    "fnnname = codename + \"_fnn_model\"\n",
    "\n",
    "total_loss_name = codename + \"_total_loss\"\n",
    "acc_name = codename + \"_accuracy\"\n",
    "soft_loss_name = codename + \"_softmax_loss\"\n",
    "ad_disc_loss_name = codename + \"_adaptivediscriminant_loss\"\n",
    "ad_cen_loss_name = codename + \"_adaptivecenter_loss\"\n",
    "\n",
    "result_name = codename + \"_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "instance_datasets = Datasets(DATASET, BATCH_SIZE, NUM_WORKERS)\n",
    "data_sets = instance_datasets.create()\n",
    "\n",
    "trainloader = data_sets[0]\n",
    "testloader = data_sets[1]\n",
    "classes = data_sets[2]\n",
    "based_labels = data_sets[3]\n",
    "trainset = data_sets[4]\n",
    "testset = data_sets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and criterions\n",
    "model = Net(FEATURE, OUTPUTS).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=SCHEDULER_STEPS, gamma=SCHEDULER_GAMMA)\n",
    "\n",
    "soft_criterion = nn.CrossEntropyLoss()\n",
    "disc_criterion = AdaptiveDiscriminantLoss(ALPHA1, len(classes), device)\n",
    "cen_criterion = AdaptiveCenterLoss(ALPHA2, len(classes), FEATURE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit for training and test\n",
    "fit = NetworkFit(model, optimizer, soft_criterion, disc_criterion, cen_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to manage all scores\n",
    "loss = Score()\n",
    "loss_s = Score()\n",
    "loss_d = Score()\n",
    "loss_c = Score()\n",
    "correct = Score()\n",
    "score_loss = [loss, loss_s, loss_d, loss_c]\n",
    "score_correct = [correct]\n",
    "sc = ScoreCalc(score_loss, score_correct, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test\n",
    "for epoch in range(EPOCH):\n",
    "    print('epoch', epoch+1)\n",
    "\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        fit.train(inputs, labels, LAMBDA1, LAMBDA2)\n",
    "    \n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        losses, corrects = fit.test(inputs, labels, LAMBDA1, LAMBDA2)\n",
    "        \n",
    "        sc.calc_sum(losses, corrects)\n",
    "    \n",
    "    sc.score_print(len(trainset))\n",
    "    sc.score_append(len(trainset))\n",
    "    sc.score_del()\n",
    "    \n",
    "    for (inputs, labels) in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        losses, corrects = fit.test(inputs, labels, LAMBDA1, LAMBDA2)\n",
    "        \n",
    "        sc.calc_sum(losses, corrects)\n",
    "    \n",
    "    sc.score_print(len(testset), train = False)\n",
    "    sc.score_append(len(testset), train = False)\n",
    "    sc.score_del()\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scores\n",
    "train_losses, train_corrects = sc.get_value()\n",
    "test_losses, test_corrects = sc.get_value(train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the glaphs of the scores\n",
    "torch.save(model.state_dict(), fnnname + '.pth')\n",
    "\n",
    "savescore.plot_score(EPOCH, train_losses[0], test_losses[0], y_lim = 2.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'total loss', filename = total_loss_name)\n",
    "\n",
    "savescore.plot_score(EPOCH, train_corrects[0], test_corrects[0], y_lim = 1, y_label = 'ACCURACY', legend = ['train acc', 'test acc'], title = 'accuracy', filename = acc_name)\n",
    "\n",
    "savescore.plot_score(EPOCH, train_losses[1], test_losses[1], y_lim = 2.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'softmax loss', filename = soft_loss_name)\n",
    "\n",
    "savescore.plot_score(EPOCH, train_losses[2], test_losses[2], y_lim = 2.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'discriminant loss', filename = ad_disc_loss_name)\n",
    "\n",
    "savescore.plot_score(EPOCH, train_losses[3], test_losses[3], y_lim = 2.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'center loss', filename = ad_cen_loss_name)\n",
    "\n",
    "savescore.save_data(train_losses[0], test_losses[0], train_corrects[0], test_corrects[0], result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings and neurons of outputs for training data\n",
    "k = 0\n",
    "feature1 = np.zeros((len(trainset), FEATURE))\n",
    "feature2 = np.zeros((len(trainset), OUTPUTS))\n",
    "total_labels = np.zeros(len(trainset))\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "for (inputs, labels) in trainloader:\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outputs = fit.get_data(inputs)\n",
    "    \n",
    "    embeddings = outputs[0].detach().clone().to(cpu_device)\n",
    "    neurons = outputs[1].detach().clone().to(cpu_device)\n",
    "    \n",
    "    feature1[k: k+len(inputs)] = embeddings\n",
    "    feature2[k: k+len(inputs)] = neurons\n",
    "    total_labels[k: k+len(inputs)] = labels.detach().clone().to(cpu_device)\n",
    "    k += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the histogram for training data\n",
    "c = 6\n",
    "\n",
    "output_c = feature2[total_labels == c][:, c]\n",
    "output_other = feature2[total_labels != c][:, c]\n",
    "\n",
    "histgram.histgram([output_c, output_other], bins = 50, filename = \"histogram\", ylim = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the embeddings mapping\n",
    "plot_f = PlotFeature(based_labels)\n",
    "center = cen_criterion.get_center()\n",
    "center = center.detach().clone().to(cpu_device)\n",
    "\n",
    "if FEATURE > 2:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit(feature1)\n",
    "    feature1 = pca.transform(feature1)\n",
    "    center = pca.transform(center)\n",
    "\n",
    "plot_f.plot_feature(feature1, total_labels, center, filename = \"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
